{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh0SpvKEZel7"
      },
      "source": [
        "The following imports and functions are the same as the ones in *Laboratory 9*. We repeat them here for convenience. Also, please make sure the GPU hardware accelerator is selected in the *Change runtime type* dialog."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrKz3vPHFOQX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import collections\n",
        "\n",
        "torch.manual_seed(42);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBn_EAhNFcls"
      },
      "outputs": [],
      "source": [
        "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),\n",
        "                  cmap='Reds'):\n",
        "    \"\"\"Show heatmaps of matrices.\"\"\"\n",
        "    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize,\n",
        "                             sharex=True, sharey=True, squeeze=False)\n",
        "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n",
        "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n",
        "            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n",
        "            if i == num_rows - 1:\n",
        "                ax.set_xlabel(xlabel)\n",
        "            if j == 0:\n",
        "                ax.set_ylabel(ylabel)\n",
        "            if titles:\n",
        "                ax.set_title(titles[j])\n",
        "    fig.colorbar(pcm, ax=axes, shrink=0.6);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN4Ugzx3X_Or"
      },
      "outputs": [],
      "source": [
        "def sequence_mask(X, valid_len, value=0):\n",
        "    \"\"\"Mask irrelevant entries in sequences.\"\"\"\n",
        "    maxlen = X.size(1)\n",
        "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
        "                        device=X.device)[None, :] < valid_len[:, None]\n",
        "    X[~mask] = value\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSAa_cQmXynq"
      },
      "outputs": [],
      "source": [
        "def masked_softmax(X, valid_lens):\n",
        "    \"\"\"Perform softmax operation by masking elements on the last axis.\"\"\"\n",
        "    # `X`: 3D tensor, `valid_lens`: 1D or 2D tensor\n",
        "    if valid_lens is None:\n",
        "        return nn.functional.softmax(X, dim=-1)\n",
        "    else:\n",
        "        shape = X.shape\n",
        "        if valid_lens.dim() == 1:\n",
        "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
        "        else:\n",
        "            valid_lens = valid_lens.reshape(-1)\n",
        "        # On the last axis, replace masked elements with a very large negative\n",
        "        # value, whose exponentiation outputs 0\n",
        "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
        "                          value=-1e6)\n",
        "        return F.softmax(X.reshape(shape), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9nEHmdPaSqs"
      },
      "outputs": [],
      "source": [
        "class DotProductAttention(nn.Module):\n",
        "    \"\"\"Scaled dot product attention.\"\"\"\n",
        "    def __init__(self, dropout, **kwargs):\n",
        "        super(DotProductAttention, self).__init__(**kwargs)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # Shape of `queries` is: (`batch_size`, no. of queries, `d`)\n",
        "    # Shape of `keys` is: (`batch_size`, no. of key-value pairs, `d`)\n",
        "    # Shape of `values` is: (`batch_size`, no. of key-value pairs, value\n",
        "    # dimension)\n",
        "    # Shape of `valid_lens`: (`batch_size`,) or (`batch_size`, no. of queries)\n",
        "    def forward(self, queries, keys, values, valid_lens=None):\n",
        "        d = queries.shape[-1]\n",
        "        # Use `keys.transpose(1,2)` to swap the last two dimensions of `keys`\n",
        "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
        "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
        "        return torch.bmm(self.dropout(self.attention_weights), values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHzHP7cVdVw4"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"The base decoder interface for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "\n",
        "    def init_state(self, enc_outputs, *args):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIM4remedMWz"
      },
      "outputs": [],
      "source": [
        "class AttentionDecoder(Decoder):\n",
        "    \"\"\"The base attention-based decoder interface.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionDecoder, self).__init__(**kwargs)\n",
        "\n",
        "    @property\n",
        "    def attention_weights(self):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGTI_sHneH8G"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"The base encoder interface for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "\n",
        "    def forward(self, X, *args):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqwuucHg6d0O"
      },
      "outputs": [],
      "source": [
        "def try_gpu(i=0):\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RjVRKbf5HDN"
      },
      "outputs": [],
      "source": [
        "class Vocab:\n",
        "    \"\"\"Vocabulary for text.\"\"\"\n",
        "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
        "        if tokens is None:\n",
        "            tokens = []\n",
        "        if reserved_tokens is None:\n",
        "            reserved_tokens = []\n",
        "        # Sort according to frequencies\n",
        "        counter = count_corpus(tokens)\n",
        "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
        "                                   reverse=True)\n",
        "        # The index for the unknown token is 0\n",
        "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
        "        self.token_to_idx = {token: idx\n",
        "                             for idx, token in enumerate(self.idx_to_token)}\n",
        "        for token, freq in self._token_freqs:\n",
        "            if freq < min_freq:\n",
        "                break\n",
        "            if token not in self.token_to_idx:\n",
        "                self.idx_to_token.append(token)\n",
        "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_to_token)\n",
        "\n",
        "    def __getitem__(self, tokens):\n",
        "        if not isinstance(tokens, (list, tuple)):\n",
        "            return self.token_to_idx.get(tokens, self.unk)\n",
        "        return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "    def to_tokens(self, indices):\n",
        "        if not isinstance(indices, (list, tuple)):\n",
        "            return self.idx_to_token[indices]\n",
        "        return [self.idx_to_token[index] for index in indices]\n",
        "\n",
        "    @property\n",
        "    def unk(self):  # Index for the unknown token\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def token_freqs(self):  # Token frequencies\n",
        "        return self._token_freqs\n",
        "\n",
        "def count_corpus(tokens):\n",
        "    \"\"\"Count token frequencies.\"\"\"\n",
        "    # Here `tokens` is a 1D list or 2D list\n",
        "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
        "        # Flatten a list of token lists into a list of tokens\n",
        "        tokens = [token for line in tokens for token in line]\n",
        "    return collections.Counter(tokens)\n",
        "\n",
        "def download(url, cache_dir=os.path.join('..', 'data')):\n",
        "    \"\"\"Download a file, return the local filename.\"\"\"\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
        "    if os.path.exists(fname):\n",
        "        with open(fname, 'rb') as f:\n",
        "            while True:\n",
        "                data = f.read(1048576)\n",
        "                if not data:\n",
        "                    break\n",
        "        return fname\n",
        "    print(f'Downloading {fname} from {url}...')\n",
        "    r = requests.get(url, stream=True, verify=True)\n",
        "    with open(fname, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    return fname\n",
        "\n",
        "def download_extract(url, folder=None):\n",
        "    \"\"\"Download and extract a zip file.\"\"\"\n",
        "    fname = download(url)\n",
        "    base_dir = os.path.dirname(fname)\n",
        "    data_dir, ext = os.path.splitext(fname)\n",
        "    if ext == '.zip':\n",
        "        fp = zipfile.ZipFile(fname, 'r')\n",
        "    else:\n",
        "        assert False, 'Only zip files can be extracted.'\n",
        "    fp.extractall(base_dir)\n",
        "    return os.path.join(base_dir, folder) if folder else data_dir\n",
        "\n",
        "def read_data_nmt():\n",
        "    \"\"\"Load the English-French dataset.\"\"\"\n",
        "    data_dir = download_extract('http://d2l-data.s3-accelerate.amazonaws.com/fra-eng.zip')\n",
        "    with open(os.path.join(data_dir, 'fra.txt'), 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "def preprocess_nmt(text):\n",
        "    \"\"\"Preprocess the English-French dataset.\"\"\"\n",
        "    def no_space(char, prev_char):\n",
        "        return char in set(',.!?') and prev_char != ' '\n",
        "\n",
        "    # Replace non-breaking space with space, and convert uppercase letters to\n",
        "    # lowercase ones\n",
        "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
        "    # Insert space between words and punctuation marks\n",
        "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
        "           for i, char in enumerate(text)]\n",
        "    return ''.join(out)\n",
        "\n",
        "def tokenize_nmt(text, num_examples=None):\n",
        "    \"\"\"Tokenize the English-French dataset.\"\"\"\n",
        "    source, target = [], []\n",
        "    for i, line in enumerate(text.split('\\n')):\n",
        "        if num_examples and i > num_examples:\n",
        "            break\n",
        "        parts = line.split('\\t')\n",
        "        if len(parts) == 2:\n",
        "            source.append(parts[0].split(' '))\n",
        "            target.append(parts[1].split(' '))\n",
        "    return source, target\n",
        "\n",
        "def truncate_pad(line, num_steps, padding_token):\n",
        "    \"\"\"Truncate or pad sequences.\"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps]  # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
        "\n",
        "def build_array_nmt(lines, vocab, num_steps):\n",
        "    \"\"\"Transform text sequences of machine translation into mini-batches.\"\"\"\n",
        "    lines = [vocab[l] for l in lines]\n",
        "    lines = [l + [vocab['<eos>']] for l in lines]\n",
        "    array = torch.tensor([truncate_pad(\n",
        "        l, num_steps, vocab['<pad>']) for l in lines])\n",
        "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
        "    return array, valid_len\n",
        "\n",
        "def load_array(data_arrays, batch_size, is_train=True):\n",
        "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
        "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
        "\n",
        "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
        "    \"\"\"Return the iterator and the vocabularies of the translation dataset.\"\"\"\n",
        "    text = preprocess_nmt(read_data_nmt())\n",
        "    source, target = tokenize_nmt(text, num_examples)\n",
        "    src_vocab = Vocab(source, min_freq=2,\n",
        "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "    tgt_vocab = Vocab(target, min_freq=2,\n",
        "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
        "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
        "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
        "    data_iter = load_array(data_arrays, batch_size)\n",
        "    return data_iter, src_vocab, tgt_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UekIpkBt6mUs"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"The base class for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(EncoderDecoder, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, enc_X, dec_X, *args):\n",
        "        enc_outputs = self.encoder(enc_X, *args)\n",
        "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
        "        return self.decoder(dec_X, dec_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIIaRB9B6tns"
      },
      "outputs": [],
      "source": [
        "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
        "    \"\"\"The softmax cross-entropy loss with masks.\"\"\"\n",
        "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
        "    # `label` shape: (`batch_size`, `num_steps`)\n",
        "    # `valid_len` shape: (`batch_size`,)\n",
        "    def forward(self, pred, label, valid_len):\n",
        "        weights = torch.ones_like(label)\n",
        "        weights = sequence_mask(weights, valid_len)\n",
        "        self.reduction='none'\n",
        "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
        "            pred.permute(0, 2, 1), label)\n",
        "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
        "        return weighted_loss\n",
        "\n",
        "def grad_clipping(net, theta):\n",
        "    \"\"\"Clip the gradient.\"\"\"\n",
        "    params = [p for p in net.parameters() if p.requires_grad]\n",
        "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
        "    if norm > theta:\n",
        "        for param in params:\n",
        "            param.grad[:] *= theta / norm\n",
        "\n",
        "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
        "    \"\"\"Train a model for sequence to sequence.\"\"\"\n",
        "    def xavier_init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "        if type(m) == nn.GRU:\n",
        "            for param in m._flat_weights_names:\n",
        "                if \"weight\" in param:\n",
        "                    nn.init.xavier_uniform_(m._parameters[param])\n",
        "    net.apply(xavier_init_weights)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    loss = MaskedSoftmaxCELoss()\n",
        "    net.train()\n",
        "    train_loss_all = []\n",
        "    for epoch in range(num_epochs):\n",
        "        # Sum of training loss, no. of tokens\n",
        "        total_loss = 0\n",
        "        total_tokens = 0\n",
        "        for batch in data_iter:\n",
        "            optimizer.zero_grad()\n",
        "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
        "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
        "                               device=device).reshape(-1, 1)\n",
        "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
        "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
        "            l = loss(Y_hat, Y, Y_valid_len)\n",
        "            l.sum().backward()  # Make the loss scalar for `backward`\n",
        "            grad_clipping(net, 1)\n",
        "            num_tokens = Y_valid_len.sum()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                total_loss += l.sum()\n",
        "                total_tokens += num_tokens\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            train_loss_all.append(total_loss / total_tokens)\n",
        "    print(f'loss {total_loss / total_tokens:.3f}, device {str(device)}')\n",
        "    \n",
        "    return train_loss_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjHhTOtP7UHH"
      },
      "outputs": [],
      "source": [
        "def plot_loss(train_loss_all):\n",
        "    train_loss_all = [train_loss.cpu() for train_loss in train_loss_all]\n",
        "    epochs = range(10, len(train_loss_all * 10) + 1, 10)\n",
        "    plt.plot(epochs, train_loss_all, 'b', label='Train loss') \n",
        "    plt.title('Training loss') \n",
        "    plt.xlabel('Epochs') \n",
        "    plt.ylabel('Loss') \n",
        "    plt.legend()  \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dug8iZn-8XE1"
      },
      "outputs": [],
      "source": [
        "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
        "                    device, save_attention_weights=False):\n",
        "    \"\"\"Predict for sequence to sequence.\"\"\"\n",
        "    # Set `net` to eval mode for inference\n",
        "    net.eval()\n",
        "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
        "        src_vocab['<eos>']]\n",
        "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
        "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
        "    # Add the batch axis\n",
        "    enc_X = torch.unsqueeze(\n",
        "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
        "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
        "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
        "    # Add the batch axis\n",
        "    dec_X = torch.unsqueeze(torch.tensor(\n",
        "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
        "    output_seq, attention_weight_seq = [], []\n",
        "    for _ in range(num_steps):\n",
        "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
        "        # We use the token with the highest prediction likelihood as the input\n",
        "        # of the decoder at the next time step\n",
        "        dec_X = Y.argmax(dim=2)\n",
        "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
        "        # Save attention weights\n",
        "        if save_attention_weights:\n",
        "            attention_weight_seq.append(net.decoder.attention_weights)\n",
        "        # Once the end-of-sequence token is predicted, the generation of the\n",
        "        # output sequence is complete\n",
        "        if pred == tgt_vocab['<eos>']:\n",
        "            break\n",
        "        output_seq.append(pred)\n",
        "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_ORch0n8hH1"
      },
      "outputs": [],
      "source": [
        "def bleu(pred_seq, label_seq, k):\n",
        "    \"\"\"Compute the BLEU.\"\"\"\n",
        "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
        "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
        "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
        "    for n in range(1, k + 1):\n",
        "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
        "        for i in range(len_label - n + 1):\n",
        "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
        "        for i in range(len_pred - n + 1):\n",
        "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
        "                num_matches += 1\n",
        "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
        "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJfujPH59I4N"
      },
      "source": [
        "# Multi-head attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMKuKP3y9JQw"
      },
      "source": [
        "In our implementation of *multi-head attention*, we choose the scaled dot-product attention for each head of the multi-head attention. To avoid significant growth of computational cost and parameterization cost, we set $p_q = p_k = p_v = p_o / h$. Note that the $h$ heads can be computed in parallel if we set the number of outputs of linear transformations for the query, key, and value to $p_q h = p_k h = p_v h = p_o$. In the following implementation, $p_o$ is specified via the argument `num_hiddens`.\n",
        "\n",
        "To allow for parallel computation of multiple heads, the `MultiHeadAttention` class uses two transposition functions as defined below. Specifically, the `transpose_output()` function reverses the operation of the `transpose_qkv()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY7Xwkoj9wk4"
      },
      "outputs": [],
      "source": [
        "def transpose_qkv(X, num_heads):\n",
        "    \"\"\"Transposition for parallel computation of multiple attention heads.\"\"\"\n",
        "    # Shape of input `X` is:\n",
        "    # (`batch_size`, no. of queries or key-value pairs, `num_hiddens`).\n",
        "    # Shape of output `X` is:\n",
        "    # (`batch_size`, no. of queries or key-value pairs, `num_heads`,\n",
        "    # `num_hiddens` / `num_heads`)\n",
        "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
        "\n",
        "    # Shape of output `X` is:\n",
        "    # (`batch_size`, `num_heads`, no. of queries or key-value pairs,\n",
        "    # `num_hiddens` / `num_heads`)\n",
        "    X = X.permute(0, 2, 1, 3)\n",
        "\n",
        "    # Shape of `output` is:\n",
        "    # (`batch_size` * `num_heads`, no. of queries or key-value pairs,\n",
        "    # `num_hiddens` / `num_heads`)\n",
        "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
        "\n",
        "def transpose_output(X, num_heads):\n",
        "    \"\"\"Reverse the operation of `transpose_qkv`.\"\"\"\n",
        "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
        "    X = X.permute(0, 2, 1, 3)\n",
        "    return X.reshape(X.shape[0], X.shape[1], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpCOXaKI9fQ6"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-head attention.\"\"\"\n",
        "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
        "                 num_heads, dropout, bias=False, **kwargs):\n",
        "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = DotProductAttention(dropout)\n",
        "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
        "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
        "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
        "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
        "\n",
        "    def forward(self, queries, keys, values, valid_lens):\n",
        "        # Shape of `queries`, `keys`, or `values` is:\n",
        "        # (`batch_size`, no. of queries or key-value pairs, `num_hiddens`)\n",
        "        # Shape of `valid_lens` is:\n",
        "        # (`batch_size`,) or (`batch_size`, no. of queries)\n",
        "        # After transposing, shape of output `queries`, `keys`, or `values` is:\n",
        "        # (`batch_size` * `num_heads`, no. of queries or key-value pairs,\n",
        "        # `num_hiddens` / `num_heads`)\n",
        "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
        "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
        "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
        "\n",
        "        if valid_lens is not None:\n",
        "            # On axis 0, copy the first item (scalar or vector) for\n",
        "            # `num_heads` times, then copy the next item, and so on\n",
        "            valid_lens = torch.repeat_interleave(\n",
        "                valid_lens, repeats=self.num_heads, dim=0)\n",
        "\n",
        "        # Shape of `output` is: (`batch_size` * `num_heads`, no. of queries,\n",
        "        # `num_hiddens` / `num_heads`)\n",
        "        output = self.attention(queries, keys, values, valid_lens)\n",
        "\n",
        "        # Shape of `output_concat` is:\n",
        "        # (`batch_size`, no. of queries, `num_hiddens`)\n",
        "        output_concat = transpose_output(output, self.num_heads)\n",
        "        return self.W_o(output_concat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Wy_K4w90uz"
      },
      "source": [
        "Let us test our implemented `MultiHeadAttention` class using a toy example, where keys and values are the same. As a result, the shape of the multi-head attention output is (`batch_size`, `num_queries`, `num_hiddens`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLMODk1P95mE",
        "outputId": "403ed3fe-f049-41c7-d301-4179df447caa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiHeadAttention(\n",
              "  (attention): DotProductAttention(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (W_q): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (W_k): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (W_v): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (W_o): Linear(in_features=100, out_features=100, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_hiddens, num_heads = 100, 5\n",
        "attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,\n",
        "                               num_hiddens, num_heads, 0.5)\n",
        "attention.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alXzAXMK98Od",
        "outputId": "2466eba8-3aa3-4849-fc0f-d6b27d2b7beb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 100])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size, num_queries, num_kvpairs, valid_lens = 2, 4, 6, torch.tensor([3, 2])\n",
        "X = torch.ones((batch_size, num_queries, num_hiddens))\n",
        "Y = torch.ones((batch_size, num_kvpairs, num_hiddens))\n",
        "attention(X, Y, Y, valid_lens).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HV_QBO6FB99"
      },
      "source": [
        "# Self-attention and positional encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABcknmz2FE6l"
      },
      "source": [
        "Using multi-head attention, the following code snippet computes the *self-attention* of a tensor with shape (batch size, number of time steps or sequence length in tokens, $d$). The output tensor has the same shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7le6OoUFFqLY",
        "outputId": "8b55d97a-bd62-4cf0-acc5-8d05e93b26d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultiHeadAttention(\n",
              "  (attention): DotProductAttention(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (W_q): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (W_k): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (W_v): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (W_o): Linear(in_features=100, out_features=100, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_hiddens, num_heads = 100, 5\n",
        "attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,\n",
        "                               num_hiddens, num_heads, 0.5)\n",
        "attention.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVFooKoAFvhQ",
        "outputId": "afa6252a-135f-4e86-84e4-b8b26b5b1916"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 100])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size, num_queries, valid_lens = 2, 4, torch.tensor([3, 2])\n",
        "X = torch.ones((batch_size, num_queries, num_hiddens))\n",
        "attention(X, X, X, valid_lens).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bI5ui4EF_Oi"
      },
      "source": [
        "Suppose that the input representation $\\boldsymbol{X} \\in \\mathbb{R}^{n \\times d}$ contains the $d$-dimensional embeddings for $n$ tokens of a sequence. The *positional encoding* outputs $\\boldsymbol{X} + \\boldsymbol{P}$ using a positional embedding matrix $\\mathbf{P} \\in \\mathbb{R}^{n \\times d}$ of the same shape, whose element on the $i$th row and the $(2j)$th or the $(2j + 1)$th column is:\n",
        "\n",
        "$$\\begin{aligned} p_{i, 2j} &= \\sin\\left(\\frac{i}{10000^{2j/d}}\\right),\\\\p_{i, 2j+1} &= \\cos\\left(\\frac{i}{10000^{2j/d}}\\right).\\end{aligned}$$\n",
        "\n",
        "At first glance, this trigonometric-function design looks weird. Before explanations of this design, let us first implement it in the following `PositionalEncoding` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeoEoB_AGYkc"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Positional encoding.\"\"\"\n",
        "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Create a long enough `P`\n",
        "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
        "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
        "            -1, 1) / torch.pow(10000, torch.arange(\n",
        "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
        "        self.P[:, :, 0::2] = torch.sin(X)\n",
        "        self.P[:, :, 1::2] = torch.cos(X)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
        "        return self.dropout(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQUR-VehGcRC"
      },
      "source": [
        "In the positional embedding matrix $\\boldsymbol{P}$, rows correspond to positions within a sequence and columns represent different positional encoding dimensions. In the example below, we can see that the $6$th and the $7$th columns of the positional embedding matrix have a higher frequency than the $8$th and the $9$th columns. The offset between the $6$th and the $7$th (same for the $8$th and the $9$th) columns is due to the alternation of sine and cosine functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHOvoQbDG8Vf",
        "outputId": "6ad574fe-9666-426b-d2f8-5535c35c21f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
            "  import sys\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x180 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "encoding_dim, num_steps = 32, 60\n",
        "pos_encoding = PositionalEncoding(encoding_dim, 0)\n",
        "pos_encoding.eval()\n",
        "X = pos_encoding(torch.zeros((1, num_steps, encoding_dim)))\n",
        "P = pos_encoding.P[:, :X.shape[1], :]\n",
        "plt.figure(figsize=(6, 2.5))\n",
        "plt.plot(torch.arange(num_steps), P[0, :, 6].T, '-', label=\"Col 6\")\n",
        "plt.plot(torch.arange(num_steps), P[0, :, 7].T, 'm--', label=\"Col 7\")\n",
        "plt.plot(torch.arange(num_steps), P[0, :, 8].T, 'g-.', label=\"Col 8\")\n",
        "plt.plot(torch.arange(num_steps), P[0, :, 9].T, 'r:', label=\"Col 9\")\n",
        "plt.xlabel('Row (position)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKu4eOUnJYLK"
      },
      "source": [
        "To see how the monotonically decreased frequency along the encoding dimension relates to absolute positional information, let us print out the binary representations of $0, 1, \\ldots, 7$. As we can see, the lowest bit, the second-lowest bit, and the third-lowest bit alternate on every number, every two numbers, and every four numbers, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXGikwtwJhLQ",
        "outputId": "40f27bb9-f5a6-406a-80ac-052eec63b76c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 in binary is 000\n",
            "1 in binary is 001\n",
            "2 in binary is 010\n",
            "3 in binary is 011\n",
            "4 in binary is 100\n",
            "5 in binary is 101\n",
            "6 in binary is 110\n",
            "7 in binary is 111\n"
          ]
        }
      ],
      "source": [
        "for i in range(8):\n",
        "    print(f'{i} in binary is {i:>03b}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3wWm4RCJjUO"
      },
      "source": [
        "In binary representations, a higher bit has a lower frequency than a lower bit. Similarly, as demonstrated in the heat map below, the positional encoding decreases frequencies along the encoding dimension by using trigonometric functions. Since the outputs are float numbers, such continuous representations are more space-efficient than binary representations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5qGtBQTJvIk",
        "outputId": "0a050059-e973-4733-f6f7-7540477c4322"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 252x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "P = P[0, :, :].unsqueeze(0).unsqueeze(0)\n",
        "show_heatmaps(P, xlabel='Column (encoding dimension)',\n",
        "              ylabel='Row (position)', figsize=(3.5, 4), cmap='Blues')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w11fM4uwLMpr"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZuqRPaMLOkH"
      },
      "source": [
        "We have already implemented multi-head attention based on scaled dot-products and positional encoding above. In the following, we will implement the rest of the *transformer* model.\n",
        "\n",
        "The position-wise feed-forward network transforms the representation at all the sequence positions using the same MLP. This is why we call it *position-wise*. In the implementation below, the input `X` with shape (batch size, number of time steps or sequence length in tokens, number of hidden units or feature dimension) will be transformed by a two-layer MLP into an output tensor of shape\n",
        "(batch size, number of time steps, `ffn_num_outputs`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lnyMTq7LvYk"
      },
      "outputs": [],
      "source": [
        "class PositionWiseFFN(nn.Module):\n",
        "    \"\"\"Position-wise feed-forward network.\"\"\"\n",
        "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
        "                 **kwargs):\n",
        "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
        "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.dense2(self.relu(self.dense1(X)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayHSP8SyLx9n"
      },
      "source": [
        "The following example shows that the innermost dimension of a tensor changes to\n",
        "the number of outputs in the position-wise feed-forward network. Since the same MLP transforms at all the positions, when the inputs at all these positions are the same, their outputs are also identical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL_Hb6_-L8S8",
        "outputId": "dcba37d5-93b9-4544-d401-907db7f201ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.3745,  0.0313, -0.0469, -0.2155,  0.6962, -0.0252,  0.1524,  0.2927],\n",
              "        [ 0.3745,  0.0313, -0.0469, -0.2155,  0.6962, -0.0252,  0.1524,  0.2927],\n",
              "        [ 0.3745,  0.0313, -0.0469, -0.2155,  0.6962, -0.0252,  0.1524,  0.2927]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ffn = PositionWiseFFN(4, 4, 8)\n",
        "ffn.eval()\n",
        "ffn(torch.ones((2, 3, 4)))[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_geplkJMBfQ"
      },
      "source": [
        "Now, let us focus on the \"Add & norm\" component. This is a residual connection immediately followed by layer normalization. Both are key to effective deep architectures.\n",
        "\n",
        "Layer normalization is the same as batch normalization, except that the former normalizes across the feature dimension. Despite its pervasive applications\n",
        "in computer vision, batch normalization is usually empirically less effective than layer normalization in natural language processing tasks, whose inputs are often variable-length sequences.\n",
        "\n",
        "The following code snippet compares the normalization across different dimensions by layer normalization and batch normalization, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97atB222MVtO",
        "outputId": "ac97b8a2-306a-4f8b-a216-f9436070cdfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer norm: tensor([[-1.0000,  1.0000],\n",
            "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>) \n",
            "Batch norm: tensor([[-1.0000, -1.0000],\n",
            "        [ 1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward0>)\n"
          ]
        }
      ],
      "source": [
        "ln = nn.LayerNorm(2)\n",
        "bn = nn.BatchNorm1d(2)\n",
        "X = torch.tensor([[1, 2], [2, 3]], dtype=torch.float32)\n",
        "# Compute mean and variance from `X` in the training mode\n",
        "print('Layer norm:', ln(X), '\\nBatch norm:', bn(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiOK_TGUMgf2"
      },
      "source": [
        "Now, we can implement the `AddNorm` class using a residual connection followed by layer normalization. Dropout is also applied for regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUUQo-9gMlWW"
      },
      "outputs": [],
      "source": [
        "class AddNorm(nn.Module):\n",
        "    \"\"\"Residual connection followed by layer normalization.\"\"\"\n",
        "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
        "        super(AddNorm, self).__init__(**kwargs)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.ln = nn.LayerNorm(normalized_shape)\n",
        "\n",
        "    def forward(self, X, Y):\n",
        "        return self.ln(self.dropout(Y) + X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ2yMLAzMn-l"
      },
      "source": [
        "The residual connection requires that the two inputs are of the same shape, so that the output tensor also has the same shape after the addition operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUQNNi9RMuYA",
        "outputId": "65c4b872-8941-4836-eda7-ee9796a5894a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "add_norm = AddNorm([3, 4], 0.5) # `normalized_shape` is input.size()[1:]\n",
        "add_norm.eval()\n",
        "add_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4))).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJTL_xBDNFjA"
      },
      "source": [
        "With all the essential components to assemble the transformer encoder, let us start by implementing a single layer within the encoder. The following `EncoderBlock` class contains two sublayers: multi-head self-attention and position-wise feed-forward networks, where a residual connection followed by layer normalization is employed around both sublayers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNBCzgaVNOOb"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    \"\"\"Transformer encoder block.\"\"\"\n",
        "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
        "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
        "                 dropout, use_bias=False, **kwargs):\n",
        "        super(EncoderBlock, self).__init__(**kwargs)\n",
        "        self.attention = MultiHeadAttention(\n",
        "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
        "            use_bias)\n",
        "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
        "        self.ffn = PositionWiseFFN(\n",
        "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
        "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
        "\n",
        "    def forward(self, X, valid_lens):\n",
        "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
        "        return self.addnorm2(Y, self.ffn(Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVaOtGzgNX8U"
      },
      "source": [
        "As we can see, any layer in the transformer encoder does not change the shape of its input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcULB1j4Ndio",
        "outputId": "46f2bc61-8d97-4bcc-900c-bbdefe113ae6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 100, 24])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = torch.ones((2, 100, 24))\n",
        "valid_lens = torch.tensor([3, 2])\n",
        "encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
        "encoder_blk.eval()\n",
        "encoder_blk(X, valid_lens).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd111mA5Nhp-"
      },
      "source": [
        "In the following transformer encoder implementation, we stack `num_layers` instances of the above `EncoderBlock` classes. Since we use the fixed positional encoding whose values are always between $-1$ and $1$, we multiply values of the learnable input embeddings by the square root of the embedding dimension to rescale before summing up the input embedding and the positional encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKZGH8dmNwTF"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(Encoder):\n",
        "    \"\"\"Transformer encoder.\"\"\"\n",
        "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
        "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
        "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
        "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
        "        self.blks = nn.Sequential()\n",
        "        for i in range(num_layers):\n",
        "            self.blks.add_module(\"block\"+str(i),\n",
        "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
        "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
        "                             num_heads, dropout, use_bias))\n",
        "\n",
        "    def forward(self, X, valid_lens, *args):\n",
        "        # Since positional encoding values are between -1 and 1, the embedding\n",
        "        # values are multiplied by the square root of the embedding dimension\n",
        "        # to rescale before they are summed up\n",
        "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
        "        self.attention_weights = [None] * len(self.blks)\n",
        "        for i, blk in enumerate(self.blks):\n",
        "            X = blk(X, valid_lens)\n",
        "            self.attention_weights[\n",
        "                i] = blk.attention.attention.attention_weights\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAMZ_0W0N2QY"
      },
      "source": [
        "Below we specify hyperparameters to create a two-layer transformer encoder. The shape of the transformer encoder output is (batch size, number of time steps, `num_hiddens`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlCCSZKBN52V",
        "outputId": "8ff0b9be-20c5-46ff-829e-71d612fd40ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 100, 24])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder = TransformerEncoder(\n",
        "    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
        "encoder.eval()\n",
        "encoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvwAaNwNOC1i"
      },
      "source": [
        "The transformer decoder is also composed of multiple identical layers. Each layer is implemented in the following `DecoderBlock` class, which contains three sublayers: decoder self-attention, encoder-decoder attention, and position-wise feed-forward networks. These sublayers employ a residual connection around them, followed by layer normalization.\n",
        "\n",
        "In the masked multi-head decoder self-attention (the first sublayer), queries, keys, and values all come from the outputs of the previous decoder layer. When training sequence-to-sequence models, tokens at all the positions (time steps) of the output sequence are known. However, during prediction, the output sequence is generated token by token; thus, at any decoder time step, only the generated tokens can be used in the decoder self-attention. To preserve auto-regression in the decoder, its masked self-attention specifies `dec_valid_lens`, so that any query only attends to all positions in the decoder up to the query position."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-tUiL8lPD-B"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    # The `i`-th block in the decoder\n",
        "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
        "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
        "                 dropout, i, **kwargs):\n",
        "        super(DecoderBlock, self).__init__(**kwargs)\n",
        "        self.i = i\n",
        "        self.attention1 = MultiHeadAttention(\n",
        "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
        "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
        "        self.attention2 = MultiHeadAttention(\n",
        "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
        "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
        "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
        "                                   num_hiddens)\n",
        "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
        "        # During training, all the tokens of any output sequence are processed\n",
        "        # at the same time, so `state[2][self.i]` is `None` as initialized.\n",
        "        # When decoding any output sequence token by token during prediction,\n",
        "        # `state[2][self.i]` contains representations of the decoded output at\n",
        "        # the `i`-th block up to the current time step\n",
        "        if state[2][self.i] is None:\n",
        "            key_values = X\n",
        "        else:\n",
        "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
        "        state[2][self.i] = key_values\n",
        "        if self.training:\n",
        "            batch_size, num_steps, _ = X.shape\n",
        "            # Shape of `dec_valid_lens` is: (`batch_size`, `num_steps`), where\n",
        "            # every row is [1, 2, ..., `num_steps`]\n",
        "            dec_valid_lens = torch.arange(\n",
        "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
        "        else:\n",
        "            dec_valid_lens = None\n",
        "\n",
        "        # Self-attention\n",
        "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
        "        Y = self.addnorm1(X, X2)\n",
        "        # Encoder-decoder attention. Shape of `enc_outputs` is:\n",
        "        # (`batch_size`, `num_steps`, `num_hiddens`)\n",
        "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
        "        Z = self.addnorm2(Y, Y2)\n",
        "        return self.addnorm3(Z, self.ffn(Z)), state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhTpM00APLqw"
      },
      "source": [
        "To facilitate scaled dot-product operations in the encoder-decoder attention and addition operations in the residual connections, the feature dimension (`num_hiddens`) of the decoder is the same as that of the encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEPLFL-FP-gO",
        "outputId": "16f925c6-ab0f-4742-d44b-497da400a533"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 100, 24])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoder_blk = DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0)\n",
        "decoder_blk.eval()\n",
        "X = torch.ones((2, 100, 24))\n",
        "state = [encoder_blk(X, valid_lens), valid_lens, [None]]\n",
        "decoder_blk(X, state)[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZMeZFvsQAmo"
      },
      "source": [
        "Now, we construct the entire transformer decoder composed of `num_layers` instances of `DecoderBlock`. In the end, a fully-connected layer computes the prediction for all the `vocab_size` possible output tokens. Both of the decoder self-attention weights and the encoder-decoder attention weights are stored for later visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izKHdDHHQPwQ"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(AttentionDecoder):\n",
        "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
        "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
        "                 num_heads, num_layers, dropout, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
        "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
        "        self.blks = nn.Sequential()\n",
        "        for i in range(num_layers):\n",
        "            self.blks.add_module(\"block\"+str(i),\n",
        "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
        "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
        "                             num_heads, dropout, i))\n",
        "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
        "\n",
        "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
        "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
        "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
        "        for i, blk in enumerate(self.blks):\n",
        "            X, state = blk(X, state)\n",
        "            # Decoder self-attention weights\n",
        "            self._attention_weights[0][\n",
        "                i] = blk.attention1.attention.attention_weights\n",
        "            # Encoder-decoder attention weights\n",
        "            self._attention_weights[1][\n",
        "                i] = blk.attention2.attention.attention_weights\n",
        "        return self.dense(X), state\n",
        "\n",
        "    @property\n",
        "    def attention_weights(self):\n",
        "        return self._attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E4zGR_wQVKX"
      },
      "source": [
        "Let us instantiate an encoder-decoder model by following the transformer architecture. Here, we specify that both the transformer encoder and the transformer decoder have $2$ layers using $4$-head attention. We train the transformer model for sequence to sequence learning on the English-French machine translation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqReTskmQk2k",
        "outputId": "b37f3807-f0ef-4800-f0f5-fe1d737107db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss 0.031, device cpu\n"
          ]
        }
      ],
      "source": [
        "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
        "lr, num_epochs, device = 0.005, 200, try_gpu()\n",
        "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
        "key_size, query_size, value_size = 32, 32, 32\n",
        "norm_shape = [32]\n",
        "\n",
        "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps)\n",
        "\n",
        "encoder = TransformerEncoder(\n",
        "    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
        "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
        "    num_layers, dropout)\n",
        "decoder = TransformerDecoder(\n",
        "    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
        "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
        "    num_layers, dropout)\n",
        "net = EncoderDecoder(encoder, decoder)\n",
        "train_loss_all = train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device) #1 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhz1_wCCQyW7",
        "outputId": "e781edec-401b-42ce-ab0e-ac0954bbcc8c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_loss(train_loss_all)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GADzhHRERMDf"
      },
      "source": [
        "After training, we use the transformer model to translate a few English sentences into French, and compute their BLEU scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCVxFb8-RSA7",
        "outputId": "8af980f1-9836-4ec6-8b1b-f699de2bae62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "go . => va !,  bleu 1.000\n",
            "i lost . => j'ai perdu .,  bleu 1.000\n",
            "he's calm . => il est calme .,  bleu 1.000\n",
            "i'm home . => je suis chez moi .,  bleu 1.000\n"
          ]
        }
      ],
      "source": [
        "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
        "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
        "for eng, fra in zip(engs, fras):\n",
        "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
        "        net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n",
        "    print(f'{eng} => {translation}, ',\n",
        "          f'bleu {bleu(translation, fra, k=2):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULZIF0xfRWGO"
      },
      "source": [
        "Let us visualize the transformer attention weights when translating the last English sentence into French. The shape of the encoder self-attention weights is (number of encoder layers, number of attention heads, `num_steps` or number of queries, `num_steps` or number of key-value pairs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqQjgPSWRcpY",
        "outputId": "bf13c0c1-2c08-40af-c26a-623d0ff60fda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 10, 10])"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "enc_attention_weights = torch.cat(net.encoder.attention_weights, 0).reshape((num_layers, num_heads,\n",
        "    -1, num_steps))\n",
        "enc_attention_weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Do7J6_dRvGF"
      },
      "source": [
        "In the encoder self-attention, both queries and keys come from the same input sequence. Since padding tokens do not carry meaning, with specified valid length of the input sequence, no query attends to positions of padding tokens.\n",
        "In the following, two layers of multi-head attention weights are presented row by row. Each head independently attends based on a separate representation subspaces of queries, keys, and values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "AiDXzIETR7C6",
        "outputId": "0d2a2b3d-4f99-41fa-dc70-955d5a71f1c0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 504x252 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "show_heatmaps(\n",
        "    enc_attention_weights.cpu(), xlabel='Key positions',\n",
        "    ylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)],\n",
        "    figsize=(7, 3.5))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
